{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8918c-bdae-4718-a7f6-beeb7ac8285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/MLBA_Project\"\n",
    "PRO  = f\"{BASE}/data/processed\"\n",
    "RPT  = f\"{BASE}/reports\"\n",
    "for d in [PRO, RPT]: os.makedirs(d, exist_ok=True)\n",
    "\n",
    "oof = pd.read_csv(f\"{PRO}/clf_oof_predictions.csv\", parse_dates=[\"date\"])\n",
    "oof.columns = oof.columns.str.lower()\n",
    "assert set([\"date\",\"fund_id\",\"y_true\"]).issubset(oof.columns)\n",
    "\n",
    "score_col = \"ens_weighted\" if \"ens_weighted\" in oof.columns else \"ens_tab\"\n",
    "if score_col not in oof.columns:\n",
    "    raise ValueError(\"Missing ensemble column (ens_weighted or ens_tab) in OOF.\")\n",
    "print(\"Using score column:\", score_col)\n",
    "\n",
    "mst = pd.read_csv(f\"{PRO}/clean_master_union.csv\", parse_dates=[\"date\"])\n",
    "mst.columns = mst.columns.str.lower()\n",
    "mst = mst.sort_values([\"fund_id\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "H = 63\n",
    "if \"y_excess_63d\" not in mst.columns:\n",
    "    nav_fwd = mst.groupby(\"fund_id\")[\"nav\"].shift(-H)\n",
    "    mst[\"fwd_ret_63d_fund\"] = nav_fwd / mst[\"nav\"] - 1.0\n",
    "    tri_daily = mst[[\"date\",\"tri\"]].drop_duplicates().sort_values(\"date\").copy()\n",
    "    tri_daily[\"tri_fwd\"] = tri_daily[\"tri\"].shift(-H)\n",
    "    tri_daily[\"fwd_ret_63d_bmk\"] = tri_daily[\"tri_fwd\"] / tri_daily[\"tri\"] - 1.0\n",
    "    mst = mst.merge(tri_daily[[\"date\",\"fwd_ret_63d_bmk\"]], on=\"date\", how=\"left\")\n",
    "    mst[\"y_excess_63d\"] = mst[\"fwd_ret_63d_fund\"] - mst[\"fwd_ret_63d_bmk\"]\n",
    "\n",
    "th_best = 0.30\n",
    "th_path = f\"{RPT}/threshold_choice.json\"\n",
    "if os.path.exists(th_path):\n",
    "    import json\n",
    "    try:\n",
    "        th_best = float(json.load(open(th_path))[\"threshold\"])\n",
    "        print(f\"Loaded τ from reports: {th_best:.3f}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "CFG = dict(\n",
    "    rebalance_freq=\"W-FRI\",\n",
    "    portfolio_size=8,\n",
    "    threshold=th_best,\n",
    "    max_weight=0.25,\n",
    "    tx_cost=0.002,\n",
    "    holding_days=H\n",
    ")\n",
    "\n",
    "print(\"CFG:\", CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05db9789-2e31-4299-afad-c0b057e78235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_calendar(df_dates: pd.Series, freq: str) -> pd.DatetimeIndex:\n",
    "    cal = (pd.DataFrame({\"date\": pd.to_datetime(df_dates)})\n",
    "             .dropna().drop_duplicates()\n",
    "             .set_index(\"date\").sort_index())\n",
    "    if freq.upper() in [\"BM\", \"BME\"]:\n",
    "        idx = cal.resample(\"BME\").last().dropna().index\n",
    "    else:\n",
    "        idx = cal.resample(freq).last().dropna().index\n",
    "    return idx\n",
    "\n",
    "def select_topk(day_slice: pd.DataFrame, K: int, use_threshold: bool, thr: float, max_w: float):\n",
    "    g = day_slice.dropna(subset=[score_col]).copy()\n",
    "    if use_threshold:\n",
    "        g = g.loc[g[score_col] >= thr]\n",
    "    g = g.sort_values(score_col, ascending=False).head(K)\n",
    "    if g.empty:\n",
    "        return g\n",
    "    w0 = min(1.0 / max(len(g), 1), max_w)\n",
    "    g = g.assign(weight=w0)\n",
    "    s = g[\"weight\"].sum()\n",
    "    if s > 0:\n",
    "        g[\"weight\"] = g[\"weight\"] / s\n",
    "    return g[[\"fund_id\", score_col, \"weight\"]].copy()\n",
    "\n",
    "def build_trades(oof_df: pd.DataFrame, freq: str, K: int, use_threshold: bool, thr: float, max_w: float):\n",
    "    o = oof_df[[\"date\",\"fund_id\",score_col]].dropna().copy()\n",
    "    dates = decision_calendar(o[\"date\"], freq=freq)\n",
    "    picks = []\n",
    "    for d in dates:\n",
    "        day = o.loc[o[\"date\"] == d]\n",
    "        if len(day) == 0:\n",
    "            continue\n",
    "        sel = select_topk(day, K=K, use_threshold=use_threshold, thr=thr, max_w=max_w)\n",
    "        if sel.empty:\n",
    "            continue\n",
    "        sel = sel.assign(decision_date=d)\n",
    "        picks.append(sel[[\"decision_date\",\"fund_id\",\"weight\",score_col]])\n",
    "    if not picks:\n",
    "        return o.iloc[0:0][[\"date\",\"fund_id\"]].rename(columns={\"date\":\"decision_date\"}).assign(weight=np.nan)\n",
    "    trades = pd.concat(picks, ignore_index=True)\n",
    "    trades = trades.sort_values([\"decision_date\",\"fund_id\"]).reset_index(drop=True)\n",
    "    return trades\n",
    "\n",
    "trades = build_trades(\n",
    "    oof_df=oof, freq=CFG[\"rebalance_freq\"], K=CFG[\"portfolio_size\"],\n",
    "    use_threshold=True, thr=CFG[\"threshold\"], max_w=CFG[\"max_weight\"]\n",
    ")\n",
    "print(\"Trades head:\\n\", trades.head(10))\n",
    "print(\"Decision dates:\", trades[\"decision_date\"].nunique(), \"| avg names/dec:\",\n",
    "      round(trades.groupby(\"decision_date\")[\"fund_id\"].nunique().mean(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c727e29-3488-4472-a24d-ff92c4042273",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioSimulator:\n",
    "    def __init__(self, holding_days=63, tx_cost=0.002):\n",
    "        self.H = int(holding_days)\n",
    "        self.tx = float(tx_cost)\n",
    "        self.tranche_log = pd.DataFrame(columns=[\n",
    "            \"decision_date\",\"n_pos\",\"ret_excess\",\"ret_excess_net\",\"equity\"\n",
    "        ])\n",
    "        self.position_log = []\n",
    "        self.metrics = pd.Series(dtype=float)\n",
    "\n",
    "        self._y_map = (mst[[\"date\",\"fund_id\",\"y_excess_63d\"]]\n",
    "                        .dropna().set_index([\"date\",\"fund_id\"])[\"y_excess_63d\"])\n",
    "\n",
    "    def _realized_excess(self, d, f):\n",
    "        try:\n",
    "            return float(self._y_map.loc[(d, f)])\n",
    "        except KeyError:\n",
    "            return np.nan\n",
    "\n",
    "    def run(self, trades_df: pd.DataFrame):\n",
    "        if trades_df.empty:\n",
    "            raise ValueError(\"No trades to simulate.\")\n",
    "\n",
    "        decisions = sorted(trades_df[\"decision_date\"].drop_duplicates())\n",
    "        equity = 1.0\n",
    "        rows = []\n",
    "        prev_set = set()\n",
    "\n",
    "        for d in decisions:\n",
    "            basket = trades_df.loc[trades_df[\"decision_date\"] == d].copy()\n",
    "            if basket.empty:\n",
    "                continue\n",
    "\n",
    "            basket[\"ret_excess\"] = basket.apply(lambda r: self._realized_excess(d, r[\"fund_id\"]), axis=1)\n",
    "            basket[\"ret_excess_net\"] = basket[\"ret_excess\"] - 2.0 * self.tx * basket[\"weight\"]\n",
    "\n",
    "            r_raw = float((basket[\"weight\"] * basket[\"ret_excess\"]).sum())\n",
    "            r_net = float((basket[\"weight\"] * basket[\"ret_excess_net\"]).sum())\n",
    "\n",
    "            equity *= (1.0 + r_net)\n",
    "\n",
    "            cur_set = set(basket[\"fund_id\"])\n",
    "            if prev_set:\n",
    "                added = len(cur_set - prev_set)\n",
    "                dropped = len(prev_set - cur_set)\n",
    "                denom = max((len(cur_set) + len(prev_set)) / 2.0, 1.0)\n",
    "                turnover = (added + dropped) / denom\n",
    "            else:\n",
    "                turnover = np.nan\n",
    "            prev_set = cur_set\n",
    "\n",
    "            hits = int((basket[\"ret_excess_net\"] > 0).sum())\n",
    "            self.position_log.append(basket.assign(hit=(basket[\"ret_excess_net\"] > 0).astype(int)))\n",
    "\n",
    "            rows.append(dict(\n",
    "                decision_date=d, n_pos=int(len(basket)),\n",
    "                ret_excess=r_raw, ret_excess_net=r_net,\n",
    "                turnover=turnover, hits=hits, equity=equity\n",
    "            ))\n",
    "\n",
    "        self.tranche_log = pd.DataFrame(rows).sort_values(\"decision_date\").reset_index(drop=True)\n",
    "\n",
    "        tr = self.tranche_log.copy()\n",
    "        if len(tr):\n",
    "            bdays = tr[\"decision_date\"].diff().dt.days.dropna()\n",
    "            avg_gap = float(np.nanmean(bdays)) if len(bdays) else 21.0\n",
    "            ann_factor = 252.0 / max(avg_gap, 1.0)\n",
    "\n",
    "            r = tr[\"ret_excess_net\"].fillna(0.0).values\n",
    "            mu, sd = np.mean(r), np.std(r, ddof=1) if len(r) > 1 else 0.0\n",
    "            sharpe = (mu * ann_factor) / (sd * np.sqrt(ann_factor) + 1e-12) if sd > 0 else np.nan\n",
    "\n",
    "            eq = tr[\"equity\"].values\n",
    "            peak = np.maximum.accumulate(eq)\n",
    "            dd = (eq / peak) - 1.0\n",
    "            mdd = float(np.min(dd)) if len(dd) else np.nan\n",
    "\n",
    "            hit_rate = float((r > 0).mean())\n",
    "            n_obs = int(len(r))\n",
    "\n",
    "            self.metrics = pd.Series({\n",
    "                \"annualized_excess_return\": (np.prod(1 + r) ** ann_factor) - 1.0 if len(r) else np.nan,\n",
    "                \"sharpe\": sharpe,\n",
    "                \"max_drawdown\": mdd,\n",
    "                \"hit_rate\": hit_rate,\n",
    "                \"observations\": n_obs,\n",
    "                \"avg_gap_days\": avg_gap,\n",
    "                \"avg_turnover\": float(np.nanmean(tr[\"turnover\"])) if \"turnover\" in tr else np.nan\n",
    "            })\n",
    "        return self.tranche_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51425e71-b424-4699-b08e-2ed2e2c74b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = PortfolioSimulator(holding_days=CFG[\"holding_days\"], tx_cost=CFG[\"tx_cost\"])\n",
    "curve = sim.run(trades)\n",
    "\n",
    "bt_tranche_path = f\"{RPT}/bt_tranche_log.csv\"\n",
    "curve.to_csv(bt_tranche_path, index=False)\n",
    "print(\"Saved →\", bt_tranche_path)\n",
    "\n",
    "import json\n",
    "bt_metrics_path = f\"{RPT}/bt_metrics.json\"\n",
    "json.dump(sim.metrics.to_dict(), open(bt_metrics_path,\"w\"), indent=2)\n",
    "print(\"Metrics:\\n\", sim.metrics.round(4))\n",
    "print(\"Saved →\", bt_metrics_path)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(curve[\"decision_date\"], curve[\"equity\"])\n",
    "plt.title(f\"Equity — {CFG['rebalance_freq']}, K={CFG['portfolio_size']}, τ={CFG['threshold']:.2f}\")\n",
    "plt.xlabel(\"Decision Date\"); plt.ylabel(\"Equity (excess, cum)\")\n",
    "plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "plt.savefig(f\"{RPT}/bt_equity_base.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ad1e4-7155-4d62-b263-e0dc7ee63e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = trades.sort_values([\"decision_date\",\"fund_id\"]).copy()\n",
    "\n",
    "per_tranche = (sel.groupby(\"decision_date\")[\"fund_id\"]\n",
    "                 .nunique()\n",
    "                 .rename(\"positions\")\n",
    "                 .reset_index())\n",
    "\n",
    "turn_vals = []\n",
    "prev = set()\n",
    "for d, g in sel.groupby(\"decision_date\"):\n",
    "    cur = set(g[\"fund_id\"])\n",
    "    if prev:\n",
    "        added = len(cur - prev)\n",
    "        dropped = len(prev - cur)\n",
    "        denom = max((len(cur) + len(prev)) / 2.0, 1.0)\n",
    "        val = (added + dropped) / denom\n",
    "    else:\n",
    "        val = np.nan\n",
    "    turn_vals.append((d, val))\n",
    "    prev = cur\n",
    "turn_df = pd.DataFrame(turn_vals, columns=[\"decision_date\",\"turnover\"])\n",
    "\n",
    "tl = sim.tranche_log[[\"decision_date\",\"n_pos\",\"ret_excess\",\"ret_excess_net\"]]\n",
    "turn_stats = (per_tranche\n",
    "              .merge(turn_df, on=\"decision_date\", how=\"left\")\n",
    "              .merge(tl, on=\"decision_date\", how=\"left\"))\n",
    "\n",
    "outp = f\"{RPT}/bt_turnover_stats.csv\"\n",
    "turn_stats.to_csv(outp, index=False)\n",
    "print(\"Saved →\", outp)\n",
    "print(turn_stats.describe([0.25,0.5,0.75]).round(3))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(curve[\"decision_date\"], curve[\"equity\"], label=\"Strategy (excess)\")\n",
    "plt.plot(curve[\"decision_date\"], np.ones(len(curve)), label=\"Zero-excess baseline\")\n",
    "plt.legend(); plt.title(\"Excess Equity vs Baseline\")\n",
    "plt.xlabel(\"Decision Date\"); plt.ylabel(\"Equity\")\n",
    "plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "plt.savefig(f\"{RPT}/bt_equity_vs_zero.png\", dpi=160)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39863a67-6ccf-44c4-a051-bad0659e4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def run_bt(freq, K, use_thr, thr, max_w=0.25, tx=0.002):\n",
    "    trd = build_trades(oof, freq=freq, K=K, use_threshold=use_thr, thr=thr, max_w=max_w)\n",
    "    if trd.empty:\n",
    "        return {\"freq\":freq, \"K\":K, \"use_threshold\":use_thr, \"threshold\":thr,\n",
    "                \"observations\":0, \"sharpe\":np.nan, \"annualized_excess_return\":np.nan,\n",
    "                \"max_drawdown\":np.nan, \"hit_rate\":np.nan, \"avg_turnover\":np.nan}, pd.DataFrame()\n",
    "    sim_g = PortfolioSimulator(holding_days=H, tx_cost=tx)\n",
    "    pnl = sim_g.run(trd)\n",
    "    met = sim_g.metrics.to_dict()\n",
    "    met.update({\"freq\":freq, \"K\":K, \"use_threshold\":use_thr, \"threshold\":thr,\n",
    "                \"observations\":int(len(pnl))})\n",
    "    return met, pnl.assign(cfg=f\"{freq}|K={K}|{'thr' if use_thr else 'no_thr'}={thr:.2f}\")\n",
    "\n",
    "grid_freq = [\"W-FRI\", \"BME\"]\n",
    "grid_K    = [3, 5, 8]\n",
    "grid_thr  = [0.25, 0.30, 0.35]\n",
    "\n",
    "results, curves = [], {}\n",
    "for f, K in product(grid_freq, grid_K):\n",
    "    met, pnl = run_bt(f, K, use_thr=False, thr=0.0, max_w=0.25, tx=CFG[\"tx_cost\"])\n",
    "    results.append(met); curves[(f,K,\"no_thr\")] = pnl\n",
    "\n",
    "for f, K, th in product(grid_freq, grid_K, grid_thr):\n",
    "    met, pnl = run_bt(f, K, use_thr=True, thr=th, max_w=0.25, tx=CFG[\"tx_cost\"])\n",
    "    results.append(met); curves[(f,K,f\"thr{th:.2f}\")] = pnl\n",
    "\n",
    "robust = pd.DataFrame(results)\n",
    "robust_path = f\"{RPT}/bt_robustness_grid.csv\"\n",
    "robust.to_csv(robust_path, index=False)\n",
    "print(\"Saved →\", robust_path)\n",
    "display(robust.sort_values(\"sharpe\", ascending=False).head(10).round(3))\n",
    "\n",
    "top_keys = (robust.sort_values(\"sharpe\", ascending=False).head(3)\n",
    "                 .apply(lambda r: (r[\"freq\"], r[\"K\"],\n",
    "                                   \"no_thr\" if not r[\"use_threshold\"] else f\"thr{r['threshold']:.2f}\"), axis=1)\n",
    "                 .tolist())\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "for key in top_keys:\n",
    "    tag = key[2]\n",
    "    for k, pnl in curves.items():\n",
    "        if k[0]==key[0] and k[1]==key[1] and (tag in k[2]):\n",
    "            label = f\"{k[0]}, K={k[1]}, {k[2]}\"\n",
    "            if not pnl.empty:\n",
    "                plt.plot(pnl[\"decision_date\"], pnl[\"equity\"], label=label)\n",
    "            break\n",
    "plt.title(\"Equity (top configs)\")\n",
    "plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "plt.savefig(f\"{RPT}/bt_robust_equity.png\", dpi=160)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
